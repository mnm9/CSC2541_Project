{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "import sys  \n",
    "sys.path.insert(0, '../../workspace/')\n",
    "sys.path.insert(0, '../utilities/')\n",
    "import os, os.path as osp\n",
    "import pandas as pd\n",
    "import pydicom\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import splitting\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick function to show dcm image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image (filename):\n",
    "    ds = pydicom.dcmread(filename)\n",
    "    plt.imshow(ds.pixel_array, cmap=plt.cm.bone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract info from dicom files\n",
    "#### Include study description to compare with train_labels_with_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# from cspine_hardware/cspine-det/src/etl/1_parse_dicom_uids.py\n",
    "\n",
    "DICOM_DIR = '../cspine-det/data/dicoms_072919/' #Path where DICOM files are stored\n",
    "\n",
    "#Dictionary to store DICOM files\n",
    "dcm_dict = {\n",
    "    'filepath': [],\n",
    "    'SOPClassUID': [],\n",
    "    'SOPInstanceUID' : [],\n",
    "    'StudyDate': [],\n",
    "    'Modality': [],\n",
    "    'StudyDescription': [],\n",
    "    'SeriesDescription': [],\n",
    "    'PatientID': [],\n",
    "    \"Patient'sBirthDate\": [],\n",
    "    \"Patient'sSex\": [],\n",
    "    'BodyPartExamined': [],\n",
    "    'ViewPosition': [],\n",
    "    'StudyInstanceUID':[],\n",
    "    'SeriesInstanceUID':[],\n",
    "    'PatientOrientation': []    \n",
    "}\n",
    "\n",
    "#Function to extract data from DICOM files:\n",
    "def try_to_access(dcm, name):\n",
    "    try:\n",
    "        if name=='height':\n",
    "            return (dcm.pixel_array.shape[0])\n",
    "        elif name == 'width':\n",
    "            return (dcm.pixel_array.shape[1])\n",
    "        else:\n",
    "            return(getattr(dcm, name))\n",
    "    except:\n",
    "        return(None)\n",
    "\n",
    "for root, dirs, files in tqdm(os.walk(DICOM_DIR, topdown=True)):\n",
    "    for f in files:\n",
    "        filename = osp.join(root,f)\n",
    "        dcm_dict['filepath'].append(filename.replace('../../data/',''))\n",
    "        dcm = pydicom.dcmread(filename)\n",
    "        dcm_dict['SOPClassUID'].append(try_to_access(dcm, 'SOPClassUID'))\n",
    "        dcm_dict['SOPInstanceUID'].append(try_to_access(dcm, 'SOPInstanceUID'))\n",
    "        dcm_dict['StudyDate'].append(try_to_access(dcm,'StudyDate'))\n",
    "        dcm_dict['Modality'].append(try_to_access(dcm, 'Modality'))\n",
    "        dcm_dict['StudyDescription'].append(try_to_access(dcm, 'StudyDescription'))\n",
    "        dcm_dict['SeriesDescription'].append(try_to_access(dcm, 'SeriesDescription'))\n",
    "        dcm_dict['PatientID'].append(try_to_access(dcm, 'PatientID'))\n",
    "        dcm_dict[\"Patient'sBirthDate\"].append(try_to_access(dcm, \"Patient'sBirthDate\"))\n",
    "        dcm_dict[\"Patient'sSex\"].append(try_to_access(dcm, \"Patient'sSex\"))\n",
    "        dcm_dict['BodyPartExamined'].append(try_to_access(dcm,'BodyPartExamined'))\n",
    "        dcm_dict['ViewPosition'].append(try_to_access(dcm,'ViewPosition'))\n",
    "        dcm_dict['StudyInstanceUID'].append(try_to_access(dcm, 'StudyInstanceUID'))\n",
    "        dcm_dict['SeriesInstanceUID'].append(try_to_access(dcm, 'SeriesInstanceUID'))\n",
    "        dcm_dict['PatientOrientation'].append(try_to_access(dcm, 'PatientOrientation'))\n",
    "                                                      \n",
    "dcm_df = pd.DataFrame(dcm_dict) #Save DICOM data to dataframe\n",
    "dcm_df.to_csv('DICOM_Extract_v2.csv') #Save as a CSV file                        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XR SPINE CERVICAL 2-3 VIEWS' 'XR Spine Cervical 4-5 Views'\n",
      " 'XR SPINE CERVICAL 1 VIEW' 'XR SPINE CERVICAL MYELOGRAM'\n",
      " 'XR SPINE CERVICAL 4-5 VIEWS' 'XR SPINE CERVICAL 4 VIEWS'\n",
      " 'XR SPINE MYELOGRAM CERV  THOR' 'XR SPINE CERVICAL 2-3 VWS STND PROTOCOL'\n",
      " 'CT SPINE CERVICAL W CONTRAST' 'XR Spine Cervical 2-3 Vws Stnd Protocol'\n",
      " 'XR Spine Cervical 2-3 Views' 'XR SPINE CERVICAL COMP OBLIQ  FLEXEXT'\n",
      " 'XR SPINE CERVICAL COMP FLEXEXT']\n"
     ]
    }
   ],
   "source": [
    "dcm_df = pd.read_csv('../DICOM_Extract_v2.csv')\n",
    "study_types = dcm_df['StudyDescription'].unique()\n",
    "print(study_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CT SPINE CERVICAL W CONTRAST not appropriate\n",
    "#### XR SPINE CERVICAL COMP OBLIQ  FLEXEXT not appropriate\n",
    "#### XR SPINE CERVICAL COMP FLEXEXT not appropriate\n",
    "#### XR SPINE CERVICAL MYELOGRAM not appropriate\n",
    "#### XR SPINE MYELOGRAM CERV  THOR not appropriate\n",
    "#### All other views should be able to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import brands from spreadsheet and map to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only include appropriate studies\n",
    "studies = ['XR SPINE CERVICAL 2-3 VIEWS', 'XR Spine Cervical 4-5 Views','XR SPINE CERVICAL 1 VIEW', 'XR SPINE CERVICAL 4-5 VIEWS' 'XR SPINE CERVICAL 4 VIEWS', 'XR SPINE CERVICAL 2-3 VWS STND PROTOCOL', 'XR Spine Cervical 2-3 Vws Stnd Protocol', 'XR Spine Cervical 2-3 Views']\n",
    "dcm_df = dcm_df[dcm_df['StudyDescription'].isin(studies)]\n",
    "\n",
    "# Read Excel sheet for mapping brands to patients\n",
    "df = pd.read_excel('../../hdw_merged_anon_final.xlsx')\n",
    "# Get rid of 'Unnamed' columns\n",
    "df = df[[col for col in df.columns if not re.search('Unnamed', col)]].drop_duplicates().reset_index(drop=True)\n",
    "# Now, make presence/absence of hardware labels based on Anonymized DOS\n",
    "patient_df = df[['AnonymizedPatientID', 'Anonymized DOS', 'Anterior HDW', 'Posterior HDW', 'Cage']]\n",
    "patient_df = patient_df.drop_duplicates().reset_index(drop=True)\n",
    "# Rename PatientID column to make the merge easier\n",
    "patient_df = patient_df.rename(columns={'AnonymizedPatientID':'PatientID'})\n",
    "\n",
    "# Note: Patient CSP_00015 seems to have had their Anterior HDW changed from one brand to another, with xrays for both\n",
    "# present in the dataset. This means all images for this patient are currently labeled with 2 brands.\n",
    "# Treat patient before second surgery as CSP_00015 and treat patient after second surgery as a new patient CSP00191\n",
    "# ***Assumption: any images the day of the surgery were pre-surgery and should be labeled as Atlantis\n",
    "patient_df.at[15, 'PatientID'] = 'CSP_00191'\n",
    "\n",
    "# many brands do not have enough patients to stratify them (< 3, we need 3 since we are splitting into\n",
    "# 3 sets)\n",
    "# create one 'other' category for Posterior HDW (VIRAGE, OASYS, Centerpiece/Vertex)\n",
    "# create another 'other' category for Anterior HDW (HELIX and ZEVO)\n",
    "# create a separate df for Posterior and Anterior Patients\n",
    "\n",
    "Posterior_brand_dict = {\n",
    "    \"MOUNTAINEER\" : 0,\n",
    "    \"ARCH\" : 1,\n",
    "    \"Vertex\" : 2,\n",
    "    \"VIRAGE\" : 3,\n",
    "    \"OASYS\" : 3,\n",
    "    \"Centerpiece/Vertex\" : 3\n",
    "}\n",
    "\n",
    "Anterior_brand_dict = {\n",
    "    \"ATLANTIS\" : 0,\n",
    "    \"ATLANTIS \" : 0,\n",
    "    \"ARCHON\" : 1,\n",
    "    \"MAXAN\" : 2, \n",
    "    \"HELIX\" : 3,\n",
    "    \"ZEVO\" : 3,\n",
    "}\n",
    "\n",
    "# make the order of selection Posterior, Anterior, Cage\n",
    "# this way if a patient has both Posterior and Anterior Hardware, they will be\n",
    "# identified with their Posterior hardware\n",
    "# Patients with no hardware get excluded (4 patients)\n",
    "Posterior_patients = patient_df[patient_df['Posterior HDW'].isna()==False]\n",
    "Anterior_patients = pd.concat([patient_df, Posterior_patients]).drop_duplicates(keep=False)\n",
    "Anterior_patients = Anterior_patients[Anterior_patients['Anterior HDW'].isna()==False]\n",
    "\n",
    "Posterior_patients = Posterior_patients.reset_index(drop=True)\n",
    "for index, row in Posterior_patients.iterrows():\n",
    "    Posterior_patients.at[index,'Label'] = Posterior_brand_dict[row['Posterior HDW']]\n",
    "\n",
    "Anterior_patients = Anterior_patients.reset_index(drop=True)\n",
    "for index, row in Anterior_patients.iterrows():\n",
    "    Anterior_patients.at[index,'Label'] = Anterior_brand_dict[row['Anterior HDW']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Posterior Brands : Virage, Oasys, and Centerpiece/Vertex should go in the Posterior Other Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MOUNTAINEER           13\n",
       "ARCH                   4\n",
       "Vertex                 3\n",
       "OASYS                  1\n",
       "VIRAGE                 1\n",
       "Centerpiece/Vertex     1\n",
       "Name: Posterior HDW, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_df['Posterior HDW'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Anterior Brands: Helix and Zevo should go in the Anterior Other Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ATLANTIS     122\n",
       "ARCHON        32\n",
       "MAXAN         13\n",
       "ZEVO           2\n",
       "HELIX          2\n",
       "ATLANTIS       1\n",
       "Name: Anterior HDW, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_df['Anterior HDW'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Types of Cage Brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Nuvasive    1\n",
       "Name: Cage, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_df['Cage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge brands with images, remove images before DoS, remove multilabel images,\n",
    "## remove other views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: join tables on patient ID\n",
    "Posterior_branded_dcm = pd.merge(dcm_df, Posterior_patients, on='PatientID')\n",
    "Anterior_branded_dcm = pd.merge(dcm_df, Anterior_patients, on='PatientID')\n",
    "Anterior_branded_dcm.loc[(Anterior_branded_dcm['StudyDate'] > 20150901) & (Anterior_branded_dcm['PatientID']=='CSP_00015'), 'Anterior HDW'] = 'ZEVO'\n",
    "Anterior_branded_dcm.loc[(Anterior_branded_dcm['StudyDate'] > 20150901) & (Anterior_branded_dcm['PatientID']=='CSP_00015'), 'Label'] = 3\n",
    "Anterior_branded_dcm.loc[(Anterior_branded_dcm['StudyDate'] > 20150901) & (Anterior_branded_dcm['PatientID']=='CSP_00015'), 'Anonymized DOS'] = pd.to_datetime('20150901', format='%Y%m%d')\n",
    "Anterior_branded_dcm.loc[(Anterior_branded_dcm['StudyDate'] > 20150901) & (Anterior_branded_dcm['PatientID']=='CSP_00015'), 'PatientID'] = 'CSP_00191'\n",
    "\n",
    "# Step 2: only take images after DOS\n",
    "# Do not take images before DOS as 'no hardware' because we are unsure if they came in with some hardware\n",
    "# One posterior patient is dropped because all their images were before DOS, and did not contain an implant (but were still labeled with the hardware)\n",
    "Posterior_branded_dcm = Posterior_branded_dcm[pd.to_datetime(Posterior_branded_dcm['StudyDate'], format='%Y%m%d') > Posterior_branded_dcm['Anonymized DOS']]\n",
    "Anterior_branded_dcm = Anterior_branded_dcm[pd.to_datetime(Anterior_branded_dcm['StudyDate'], format='%Y%m%d') > Anterior_branded_dcm['Anonymized DOS']]\n",
    "\n",
    "# Step 3: All patients who have multiple implants should be in the Posterior_branded_dcm df (confirmed)\n",
    "# Include a binary indicator in both dfs to show whether each image is from a patient with multiple implants\n",
    "for index, row in Posterior_branded_dcm.iterrows():\n",
    "    if (((pd.isna(row['Anterior HDW'])==False) & (pd.isna(row['Posterior HDW'])==False)) | ((pd.isna(row['Cage'])==False) & (pd.isna(row['Posterior HDW'])==False))):\n",
    "        Posterior_branded_dcm.at[index,'Multiple'] = 1\n",
    "    else:\n",
    "        Posterior_branded_dcm.at[index,'Multiple'] = 0\n",
    "\n",
    "for index, row in Anterior_branded_dcm.iterrows():\n",
    "    if (((pd.isna(row['Anterior HDW'])==False) & (pd.isna(row['Posterior HDW'])==False)) | ((pd.isna(row['Cage'])==False) & (pd.isna(row['Anterior HDW'])==False))):\n",
    "        Anterior_branded_dcm.at[index,'Multiple'] = 1\n",
    "    else:\n",
    "        Anterior_branded_dcm.at[index,'Multiple'] = 0\n",
    "\n",
    "# Step 4: Drop views that are not AP, LATERAL, LATERAL FLEX, LATERAL EXT, LL\n",
    "# Create new column indicating image view\n",
    "views = ['AP', 'LATERAL','LATERAL FLEX', 'LATERAL EXT', 'LL']\n",
    "Posterior_branded_dcm = Posterior_branded_dcm[Posterior_branded_dcm['ViewPosition'].isin(views)]\n",
    "Anterior_branded_dcm = Anterior_branded_dcm[Anterior_branded_dcm['ViewPosition'].isin(views)]\n",
    "for index, row in Posterior_branded_dcm.iterrows():\n",
    "    if (row['ViewPosition']=='AP'):\n",
    "        Posterior_branded_dcm.at[index,'View'] = 'AP'\n",
    "    else:\n",
    "        Posterior_branded_dcm.at[index,'View'] = 'L'\n",
    "for index, row in Anterior_branded_dcm.iterrows():\n",
    "    if (row['ViewPosition']=='AP'):\n",
    "        Anterior_branded_dcm.at[index,'View'] = 'AP'\n",
    "    else:\n",
    "        Anterior_branded_dcm.at[index,'View'] = 'L'\n",
    "        \n",
    "Posterior_branded_dcm = Posterior_branded_dcm.reset_index()\n",
    "Anterior_branded_dcm = Anterior_branded_dcm.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove images where pixel array does not exist (seems like they are all in anterior)\n",
    "\n",
    "no_pixels = ['../cspine-det/data/dicoms_072919/Csp_00075_20130622/IM-2297-0001-0002.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00075_20130622/IM-2297-0001-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00075_20130622/IM-2297-0001-0005.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00075_20130622/IM-2297-0001-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00001_20130622/IM-2288-0001-0005.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00001_20130622/IM-2288-0001-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00001_20130622/IM-2288-0001-0002.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00001_20130622/IM-2288-0001-0003.dcm']\n",
    "\n",
    "for dcm in no_pixels:\n",
    "    Posterior_branded_dcm = Posterior_branded_dcm.drop(Posterior_branded_dcm[Posterior_branded_dcm['filepath']==dcm].index)\n",
    "\n",
    "for dcm in no_pixels:\n",
    "    Anterior_branded_dcm = Anterior_branded_dcm.drop(Anterior_branded_dcm[Anterior_branded_dcm['filepath']==dcm].index)\n",
    "\n",
    "# remove images of teeth in posterior dataset\n",
    "posterior_teeth = ['../cspine-det/data/dicoms_072919/Csp_00095_20140411/IM-1973-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00182_20151227/IM-1432-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00157_20161113/IM-0913-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00004_20100119/IM-2548-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00004_20100119/IM-2548-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00030_20110202/IM-0010-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00133_20131111/IM-2132-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00184_20160315/IM-1299-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00183_20151221/IM-1439-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00183_20160507/IM-1202-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00085_20131127/IM-2115-0002.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00117_20160405/IM-1267-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00006_20100202/IM-2543-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00006_20100202/IM-2543-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00108_20150829/IM-1585-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00071_20130117/IM-2423-0002.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00079_20140129/IM-2040-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00079_20170129/IM-0755-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00178_20151002/IM-1539-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00147_20180107/IM-0313-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00120_20160523/IM-1167-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00185_20160716/IM-1058-0001.dcm']\n",
    "\n",
    "for dcm in posterior_teeth:\n",
    "    Posterior_branded_dcm = Posterior_branded_dcm.drop(Posterior_branded_dcm[Posterior_branded_dcm['filepath']==dcm].index)\n",
    "Posterior_branded_dcm = Posterior_branded_dcm.reset_index()\n",
    "\n",
    "# remove images of teeth in anterior dataset\n",
    "anterior_teeth = ['../cspine-det/data/dicoms_072919/Csp_00081_20130803/IM-2232-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00081_20130803/IM-2232-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00089_20140325/IM-1988-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00132_20180314/IM-0208-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00132_20180316/IM-0207-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00132_20160419/IM-1238-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00063_20121003/IM-2471-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00077_20130302/IM-2408-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00064_20120804/IM-2491-0005.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00094_20140823/IM-1868-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00179_20160531/IM-1157-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00015_20100706/IM-2500-0002.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00015_20150902/IM-1569-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00165_20160901/IM-1000-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00034_20110510/IM-2595-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00036_20110426/IM-2599-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00020_20110101/IM-0021-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00020_20110101/IM-0021-0003.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00113_20161108/IM-0916-0001.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00103_20150801/IM-1628-0004.dcm',\n",
    "'../cspine-det/data/dicoms_072919/Csp_00142_20140415/IM-1968-0001.dcm'\n",
    "]\n",
    "\n",
    "for dcm in anterior_teeth:\n",
    "    Anterior_branded_dcm = Anterior_branded_dcm.drop(Anterior_branded_dcm[Anterior_branded_dcm['filepath']==dcm].index)\n",
    "Anterior_branded_dcm = Anterior_branded_dcm.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create master csv files for images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One master file for anterior patients, one for posterior\n",
    "<br>Can create stratified files by function call to repeatedly stratify data\n",
    "<br>SeriesInstanceUID and ViewPosition are for the models that take data from the same series together (AuxLoss, HeMIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Master_Posterior_branded_dcm = Posterior_branded_dcm[['PatientID', 'filepath', 'Label', 'View', 'Multiple', 'Posterior HDW', 'SeriesInstanceUID', 'ViewPosition']]\n",
    "Master_Posterior_branded_dcm = Master_Posterior_branded_dcm.rename(columns={'Posterior HDW':'Brand'})\n",
    "Master_Anterior_branded_dcm = Anterior_branded_dcm[['PatientID', 'filepath', 'Label', 'View', 'Multiple', 'Anterior HDW', 'SeriesInstanceUID', 'ViewPosition']]\n",
    "Master_Anterior_branded_dcm = Master_Anterior_branded_dcm.rename(columns={'Anterior HDW':'Brand'})\n",
    "# Master_Posterior_branded_dcm.to_csv('Master_Posterior_HDW.csv', index=False)\n",
    "# Master_Anterior_branded_dcm.to_csv('Master_Anterior_HDW.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Train-Test-Validate Stratify function\n",
    "#### Formalized in utilities/splitting.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "\n",
    "def split_data(master, suffix):\n",
    "\n",
    "    patient_ids = master[['PatientID', 'Label']].drop_duplicates().reset_index()['PatientID']\n",
    "    patient_labels = master[['PatientID', 'Label']].drop_duplicates().reset_index()['Label']\n",
    "    Train_IDs_Strat, Test_IDs_Strat, Train_Labels_Strat, Test_Labels_Strat = sklearn.model_selection.train_test_split(patient_ids, patient_labels, test_size = 0.2, random_state=1, stratify=patient_labels)\n",
    "    # split the training set again to get a validation set\n",
    "    Train_IDs_Strat, Val_IDs_Strat, Train_Labels_Strat, Val_Labels_Strat = sklearn.model_selection.train_test_split(Train_IDs_Strat, Train_Labels_Strat, test_size = 0.2, random_state=1, stratify=Train_Labels_Strat)\n",
    "\n",
    "    Train_DCMs_Strat = master[master['PatientID'].isin(Train_IDs_Strat)]\n",
    "    Val_DCMs_Strat = master[master['PatientID'].isin(Val_IDs_Strat)]\n",
    "    Test_DCMs_Strat = master[master['PatientID'].isin(Test_IDs_Strat)]\n",
    "\n",
    "    Train_file = 'Train_' + suffix + '.csv'\n",
    "    Val_file = 'Val_' + suffix + '.csv'\n",
    "    Test_file = 'Test_' + suffix + '.csv'\n",
    "\n",
    "    Train_DCMs_Strat.to_csv(Train_file, index=False)\n",
    "    Val_DCMs_Strat.to_csv(Val_file, index=False)\n",
    "    Test_DCMs_Strat.to_csv(Test_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test-Validate Stratify Function with Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formalized in utilities/splitting.py\n",
    "\n",
    "Function will allow user which brand from the dictionary should be held out from the training and validation sets and included in the test set (based on brand name, not label, since the brand being held out may be from the 'other' category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def holdout_data(master, suffix, brand):\n",
    "\n",
    "    # remove all images from the holdout brand\n",
    "    holdouts = master[master['Brand']==brand]\n",
    "    removed = pd.concat([master, holdouts]).drop_duplicates(keep=False)\n",
    "\n",
    "    patient_ids = removed[['PatientID', 'Label', 'Brand']].drop_duplicates().reset_index()['PatientID']\n",
    "    patient_labels = removed[['PatientID', 'Label', 'Brand']].drop_duplicates().reset_index()['Label']\n",
    "\n",
    "    # split the patients in the removed set into train and test sets (80:20)\n",
    "    Train_IDs_Strat, Test_IDs_Strat, Train_Labels_Strat, Test_Labels_Strat = sklearn.model_selection.train_test_split(patient_ids, patient_labels, test_size = 0.2, random_state=1, stratify=patient_labels)\n",
    "    # split the training set again to get a validation set\n",
    "    Train_IDs_Strat, Val_IDs_Strat, Train_Labels_Strat, Val_Labels_Strat = sklearn.model_selection.train_test_split(Train_IDs_Strat, Train_Labels_Strat, test_size = 0.2, random_state=1, stratify=Train_Labels_Strat)\n",
    "\n",
    "    Train_DCMs_Strat = removed[removed['PatientID'].isin(Train_IDs_Strat)]\n",
    "    Val_DCMs_Strat = removed[removed['PatientID'].isin(Val_IDs_Strat)]\n",
    "    Test_DCMs_Strat = removed[removed['PatientID'].isin(Test_IDs_Strat)]\n",
    "\n",
    "    # add the held-out images to the test set\n",
    "    Test_DCMs_Strat = pd.concat([Test_DCMs_Strat, holdouts])\n",
    "\n",
    "    Train_file = 'Train_' + suffix + '.csv'\n",
    "    Val_file = 'Val_' + suffix + '.csv'\n",
    "    Test_file = 'Test_' + suffix + '.csv'\n",
    "\n",
    "    Train_DCMs_Strat.to_csv(Train_file, index=False)\n",
    "    Val_DCMs_Strat.to_csv(Val_file, index=False)\n",
    "    Test_DCMs_Strat.to_csv(Test_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create master files for multi-view learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_multiview_master(master, hardware):\n",
    "    # reformats the master table to so that it can be split by split_data and holdout_data\n",
    "    \n",
    "    all_series = master['SeriesInstanceUID'].unique()\n",
    "    filepath_AP = []\n",
    "    filepath_L = []\n",
    "    label = []\n",
    "    patients = []\n",
    "    multiple = []\n",
    "    brand = []\n",
    "\n",
    "    # take the master df and, for each series (set of xrays that were taken together)\n",
    "    # get the DCMs, views, patient, and brand. Each image in the tuple will be an input to one of the models\n",
    "    for series in all_series:\n",
    "        examples_df = master[master['SeriesInstanceUID']==series].reset_index()\n",
    "        \n",
    "        # find the number of AP and L views in the series and pair them up\n",
    "        # if there are an unequal numbers, the excess views will be paired with 'NaN'\n",
    "        num_AP = len(examples_df[examples_df['View']=='AP'])\n",
    "        num_L = len(examples_df[examples_df['View']=='L'])\n",
    "        max_views = max(num_AP, num_L)\n",
    "        \n",
    "        AP_files = examples_df[examples_df['View']=='AP'].reset_index()\n",
    "        L_files = examples_df[examples_df['View']=='L'].reset_index()\n",
    "        \n",
    "        for appends in range(max_views):\n",
    "            if (appends < num_AP):\n",
    "                filepath_AP.append('../' + AP_files.filepath[appends])\n",
    "            else:\n",
    "                filepath_AP.append('NaN')\n",
    "            if (appends < num_L):\n",
    "                filepath_L.append('../' + L_files.filepath[appends])\n",
    "            else:\n",
    "                filepath_L.append('NaN')\n",
    "\n",
    "            label.append(examples_df.at[0,'Label'])\n",
    "            patients.append(examples_df.at[0,'PatientID'])\n",
    "            multiple.append(examples_df.at[0,'Multiple'])\n",
    "            brand.append(examples_df.at[0,'Brand'])\n",
    "\n",
    "    views_df = pd.DataFrame({'PatientID':patients,'filepath_AP':filepath_AP, 'filepath_L':filepath_L,'Label':label,'Multiple':multiple,'Brand':brand})\n",
    "    name = 'Master_' + hardware + '_HDW_MultiView.csv'\n",
    "    views_df.to_csv(name, index=False)\n",
    "    \n",
    "    return views_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "PosteriorViews = write_multiview_master(Master_Posterior_branded_dcm, 'Posterior')\n",
    "AnteriorViews = write_multiview_master(Master_Anterior_branded_dcm, 'Anterior')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
